{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset con el comando load_files desde el directorio del programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "archivos = load_files('txt_sentoken')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creación del pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el pipeline para clasificar las reviews de las películas. Despues de probar Naive Bayes y SVM como clasificadores, elegimos al primero por obtener mejores scores en la evaluacion de la precision, valores que estan detallados en la parte de analisis de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "clasificador = Pipeline([('vector', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clasif', MultinomialNB(alpha = 1.0))])\n",
    "clasificador = clasificador.fit(archivos.data, archivos.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Configuración de parámetros - Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una selección de parámetros a variar en el pipeline para el grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {'vector__ngram_range': [(1, 1), (2, 3)], 'tfidf__use_idf': (True, False), 'clasif__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos el grid search y evaluamos el grado de exactitud del clasificador segun los parámetros elegidos, el cual es aproximadamente 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gridS_clasif = GridSearchCV(clasificador, parametros, cv = 8, n_jobs = -1)\n",
    "gridS_clasif = gridS_clasif.fit(archivos.data, archivos.target)\n",
    "\n",
    "gridS_clasif.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cuáles son, además, los mejores parámetros entre los elegidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clasif__alpha': 0.01, 'tfidf__use_idf': False, 'vector__ngram_range': (2, 3)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridS_clasif.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos diferentes maneras de aumentar la precisión del clasificador; la primera prueba fue bajar el valor de tolerancia del error, pero nos encontramos con que esto podía hasta disminuir la obtenida con los valores presentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos luego con el aumento del cv; si bien observamos que había una mejora (leve) con esto, al darle valores muy altos, la precisión llegaba a un punto en que no mejoraba y ralentizaba la ejecución del programa. cv = 8 fue la mejor opción que encontramos en un equilibrio entre tiempo y valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las diferentes pruebas nos llevaron a los parámetros presentes, logrando como mejor score 0.85. En la sección siguiente evaluaremos esta precisión con diferentes técnicas para obtener valores mas acercados a la ejecución real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluación del clasificador "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnica: Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos de entrenamiento:  1500\n",
      "Cantidad de datos de prueba:  500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(archivos.data, archivos.target, test_size = 0.25)\n",
    "\n",
    "print(\"Cantidad de datos de entrenamiento: \",len(X_train))\n",
    "print(\"Cantidad de datos de prueba: \",len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788\n"
     ]
    }
   ],
   "source": [
    "clasificador = clasificador.fit(X_train, y_train)\n",
    "\n",
    "predicted = clasificador.predict(X_test)\n",
    "\n",
    "import numpy as np\n",
    "print (np.mean (predicted == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnica: Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82   0.795  0.8075 0.81   0.7825]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "clasif = MultinomialNB()\n",
    "X = TfidfVectorizer()\n",
    "X = X.fit_transform(archivos.data)\n",
    "scores = cross_val_score(clasif, X, archivos.target, cv = 5, error_score = 'raise')\n",
    "\n",
    "print (scores)                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos valores los conseguimos con la técnica simple de validación cruzada. A continuación probaremos las variantes no estratificada, estratificada y aleatoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83508246 0.77661169 0.77027027]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv_no_estratificado = KFold(n_splits = 3)\n",
    "scores = cross_val_score(clasif, X, archivos.target, cv = cv_no_estratificado, error_score = 'raise')\n",
    "\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81586826 0.7987988  0.78528529]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv_estratificado = StratifiedKFold(n_splits = 3)\n",
    "scores = cross_val_score(clasif, X, archivos.target, cv = cv_estratificado, error_score = 'raise')\n",
    "\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.815 0.875 0.825]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv_aleatorio = ShuffleSplit(n_splits = 3)\n",
    "scores = cross_val_score(clasif, X, archivos.target, cv = cv_aleatorio, error_score = 'raise')\n",
    "\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que luego de realizar las pruebas obtenemos valores similares entre las técnicas, los cuales se encuentran todos en el intervalo (0.77 - 0.87)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Análisis de los datos obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Exactitud del clasificador = 0.8505 (limite mayor)\n",
    "\n",
    "Se ve como el clasificador implementado llega a tener una buena precision en la prediccion de datos en base al entrenamiento con el dataset. Si bien no se llega a una precision total, logramos acercarnos a un 85% (aproximadamente), lo que nos dice que los parametros elegidos fueron correctos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valor del hold out = 0.788 \n",
    "\n",
    "En una evaluacion sobre el total de las clasificaciones y utilizando la tecnica hold out, llegamos a un 78,8% de exactitud general del clasificador. Se ve reducida frente al limite mayor, pero sigue estando en un valor alto de precision. Igualmente es un valor que podria mejorarse y reducir la tasa de 25% de error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valores de validacion cruzada = (0.77 - 0.87)\n",
    "\n",
    "Con esta tecnica de evaluacion conseguimos valores de precision dentro del intervalo dado. Si se observa, es un valor parecido al obtenido con hold out, lo que es algo esperado si evaluamos con esta ultima tecnica primero.\n",
    "\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluyendo en base a los resultados obtenidos, podemos deducir que el clasificador tiene una precision de prediccion cercana al 78%, llegando en ocasiones a valores menores y mayores pero que, en general, se acercan a dicha magnitud. Es un valor bueno pero mejorable; la tasa de error del 22% es alta por lo que podria plantearse una serie diferente de parametros o aumentar el tamaño del dataset de entrenamiento."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
